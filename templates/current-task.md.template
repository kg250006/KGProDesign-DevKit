# Current Task: {{TASK_ID}}

You are executing a single task from a PRP. Focus ONLY on this task.

## Task Description
{{TASK_DESC}}

## Assigned Agent
{{TASK_AGENT}}

## Files to Modify
{{TASK_FILES}}

## Implementation Guide
```
{{TASK_PSEUDO}}
```

## Acceptance Criteria
{{TASK_CRITERIA}}

---

## Agent Delegation Strategy

**IMPORTANT:** You have access to specialized agents with domain expertise. Consider delegating this task to the most appropriate agent using the Task tool.

### Agent Selection Guide

Analyze your task and delegate to the specialist whose expertise matches:

| Agent | Delegate When Task Involves |
|-------|----------------------------|
| **frontend-engineer** | UI components, responsive design, accessibility (WCAG), state management, CSS/styling, React/Vue/Svelte, browser APIs |
| **backend-engineer** | APIs (REST/GraphQL), authentication/authorization, business logic, server-side code, Node.js/Python/Java services |
| **data-engineer** | Database schemas, migrations, SQL/NoSQL queries, data modeling, indexes, query optimization |
| **qa-engineer** | Writing tests, security review, code review, test strategies, bug investigation |
| **devops-engineer** | CI/CD pipelines, Docker, infrastructure, deployment, monitoring, GitHub Actions |
| **document-specialist** | README files, API docs, technical guides, PRDs, architecture documentation |

### How to Delegate

Use the Task tool with the appropriate `subagent_type`:

```
Task tool:
  subagent_type: "KGP:frontend-engineer"  (or backend-engineer, data-engineer, etc.)
  prompt: "Execute this task: [copy the task description and acceptance criteria]"
  description: "Implement [brief description]"
```

### Decision Framework

1. **Match the domain:** If the task is clearly frontend (UI, components, styling), delegate to frontend-engineer
2. **Match the assigned agent:** If `{{TASK_AGENT}}` is specified above, use that agent
3. **When uncertain:** Consider which agent's core competencies best match the task requirements
4. **Complex tasks:** The specialist agent has access to skills like `debug-like-expert` and `ui-visual-testing` that can help

---

## Available Skills

Specialists have access to these skills when needed:

- **debug-like-expert**: Methodical debugging with hypothesis testing (use for complex bugs)
- **ui-visual-testing**: Puppeteer-based visual validation and DOM inspection
- **deployment-expert**: Deploy to Netlify, Azure VM, FTP, or GitHub production branches
- **software-architect**: Create PRPs/PRDs and technical specifications
- **create-plans**: Hierarchical project planning

---

## Execution Instructions

1. **Assess the task domain** - Determine which specialist is best suited
2. **Delegate via Task tool** - Hand off to the appropriate agent with full context
3. **Or execute directly** - If simple enough, complete the task yourself
4. **Consider edge cases** - When the task looks relatively complete:
   - Review acceptance criteria against implementation
   - Consider boundary conditions and error states
   - Think about what could break or behave unexpectedly
   - Ensure the foundation is solid before marking complete
5. **Validate the work** - Ensure acceptance criteria are met
6. **Exit when done** - The orchestrator handles the next task

---

## Edge Case Consideration (Ralph Loop Quality Gate)

**IMPORTANT:** Before considering this task complete, apply the edge case quality gate:

### When Task Looks Complete, Ask:

1. **Boundary Conditions**
   - What happens at minimum/maximum values?
   - How does the code handle empty inputs, null values, or zero-length collections?
   - Are there off-by-one errors in loops or array access?

2. **Error States**
   - What happens when external dependencies fail?
   - Are error messages clear and actionable?
   - Does the code fail gracefully or crash unexpectedly?

3. **Concurrency & Timing**
   - Are there race conditions in async operations?
   - What if operations complete out of order?
   - Are timeouts and retries handled properly?

4. **Success Criteria Alignment**
   - Does the implementation actually satisfy EACH criterion?
   - Are there hidden assumptions that could break in production?
   - Would this pass a code review by a senior engineer?

### Quality Checkpoint

If you identify potential edge cases:
- Fix them NOW, not in a future iteration
- Add defensive code where appropriate
- Document any intentional limitations

**Remember:** Each iteration is context-isolated. The next Claude won't know what you considered. Make this iteration count.

---

## CRITICAL CONSTRAINTS

- DO NOT read the full PRP file
- DO NOT ask about other tasks
- DO NOT try to optimize by combining tasks
- Focus ONLY on this single task
- PREFER delegation to specialists over doing everything yourself
